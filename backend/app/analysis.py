"""
í†µí•© AI ë¶„ì„ ëª¨ë“ˆ
OpenAI API (ì¶”ë¡  + ê²€ì¦) í†µì¼ ì „ëµ
"""
import os
from typing import List, Dict, Optional
from datetime import datetime, date
from sqlalchemy.orm import Session
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END
import sys

# ê¸°ì¡´ ëª¨ë¸ import
backend_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

from models.models import NewsArticle, Report, ReportIndustry, ReportStock

# ==================== LLM ì„¤ì • ====================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI GPT-4 - ì¶”ë¡ ìš© (ë¹ ë¥¸ ëª¨ë¸)
llm_inference = ChatOpenAI(
    model="gpt-4o-mini",  # ë¹ ë¥´ê³  ì €ë ´í•œ ì¶”ë¡ ìš©
    temperature=0.5,  # ì°½ì˜ì  ì¶”ë¡ ì„ ìœ„í•´ ì•½ê°„ ë†’ê²Œ
    api_key=OPENAI_API_KEY
)

# OpenAI GPT-4 - ê²€ì¦ìš© (ì •í™•í•˜ê³  ì—„ê²©)
llm_validation = ChatOpenAI(
    model="gpt-4o-mini",  # ë˜ëŠ” "gpt-4o" (ë” ì •í™•í•˜ì§€ë§Œ ë¹„ì‹¸)
    temperature=0.1,  # ê²€ì¦ì€ ì¼ê´€ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ë‚®ê²Œ
    api_key=OPENAI_API_KEY
)

print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
print(f"   - ì¶”ë¡  ì—”ì§„: OpenAI GPT-4o-mini")
print(f"   - ê²€ì¦ ì—”ì§„: OpenAI GPT-4o-mini")

# ==================== Pydantic Models ====================

class StockInfo(BaseModel):
    """1ì°¨ ìˆ˜í˜œì£¼ ì •ë³´"""
    code: str = Field(description="ì¢…ëª©ì½”ë“œ 6ìë¦¬", pattern=r"^\d{6}$")
    name: str = Field(description="ì¢…ëª©ëª…")
    reason: str = Field(description="ìˆ˜í˜œ ì´ìœ ")
    confidence_score: float = Field(default=50.0, ge=0, le=100)
    expected_trend: str = Field(default="up", pattern="^(up|down|neutral)$")

class SideEffectInfo(BaseModel):
    """2ì°¨ íŒŒê¸‰íš¨ê³¼ ì •ë³´"""
    sector: str = Field(description="íŒŒê¸‰ ì„¹í„° (= ì‚°ì—…ëª…)")
    logic: str = Field(description="íŒŒê¸‰ ë…¼ë¦¬")
    impact_level: str = Field(default="medium", pattern="^(high|medium|low)$")
    trend_direction: str = Field(default="positive", pattern="^(positive|negative|neutral)$")
    related_stocks: List[StockInfo] = Field(default_factory=list)

class NewsAnalysisOutput(BaseModel):
    """ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼"""
    summary: str = Field(max_length=500)
    sentiment_score: float = Field(ge=-1, le=1)
    sentiment_label: str
    key_keywords: List[str]
    issue_category: str

class PrimaryOutput(BaseModel):
    """1ì°¨ ìˆ˜í˜œì£¼ ì¶œë ¥"""
    stocks: List[StockInfo]

class SideEffectOutput(BaseModel):
    """2ì°¨ íŒŒê¸‰íš¨ê³¼ ì¶œë ¥"""
    effects: List[SideEffectInfo]

class ValidationResult(BaseModel):
    """ê²€ì¦ ê²°ê³¼"""
    is_valid: bool
    feedback: str
    confidence: float = Field(0.5, ge=0, le=1)
    issues: List[str] = Field(default_factory=list, description="ë°œê²¬ëœ ë¬¸ì œì  ë¦¬ìŠ¤íŠ¸")

# ==================== Graph State ====================

from typing import TypedDict

class AnalysisState(TypedDict):
    # ì…ë ¥
    news_articles: List[NewsArticle]
    max_primary_stocks: int
    max_side_effects: int
    max_retry: int
    
    # ë¶„ì„ ê²°ê³¼
    analysis: str
    sentiment_score: float
    sentiment_label: str
    key_keywords: List[str]
    issue_category: str
    
    # 1ì°¨ ìˆ˜í˜œì£¼
    primary_stocks: List[Dict]
    primary_feedback: str
    primary_retry_count: int
    is_primary_valid: bool
    
    # ê¸°ìˆ ì  ê²€ì¦ (ì°¨íŠ¸)
    technical_rejected: List[Dict]  # ì°¨íŠ¸ ê³¼ì—´ë¡œ íƒˆë½í•œ ì¢…ëª©ë“¤
    
    # 2ì°¨ íŒŒê¸‰íš¨ê³¼
    side_effects: List[Dict]
    side_effect_feedback: str
    side_effect_retry_count: int
    is_side_effect_valid: bool
    
    # ë©”íƒ€ë°ì´í„°
    start_time: datetime
    llm_call_count: int
    openai_calls: int
    warnings: List[str]

# ==================== LangGraph Nodes ====================

def analyze_news_node(state: AnalysisState):
    """[1] ë‰´ìŠ¤ ë¶„ì„ (OpenAI GPT ì‚¬ìš©)"""
    print("--- [1] ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘ (OpenAI GPT) ---")
    
    news_articles = state["news_articles"]
    
    # ë‰´ìŠ¤ ìš”ì•½ (ìµœëŒ€ 10ê°œ)
    news_summary = "\n\n".join([
        f"[{i+1}] ì œëª©: {article.title}\nì¶œì²˜: {article.source}\në‚´ìš©: {article.content[:300] if article.content else 'ë‚´ìš© ì—†ìŒ'}"
        for i, article in enumerate(news_articles[:10])
    ])
    
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

[ë‰´ìŠ¤ ê¸°ì‚¬ë“¤]
{news_summary}

[ë¶„ì„ ìš”êµ¬ì‚¬í•­]
1. ì „ì²´ ë‰´ìŠ¤ì˜ í•µì‹¬ ì´ìŠˆë¥¼ 200ì ì´ë‚´ë¡œ ìš”ì•½
2. ì‹œì¥ ê°ì„± ì ìˆ˜ (-1.0=ë§¤ìš°ë¶€ì • ~ 1.0=ë§¤ìš°ê¸ì •)
3. ê°ì„± ë¼ë²¨ (ë§¤ìš°ê¸ì •/ê¸ì •/ì¤‘ë¦½/ë¶€ì •/ë§¤ìš°ë¶€ì •)
4. í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì¶”ì¶œ (ì£¼ì‹ íˆ¬ì ê´€ë ¨)
5. ì´ìŠˆ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…/ì‹¤ì /ê¸°ìˆ /ê¸ˆë¦¬/ì§€ì •í•™/ê¸°íƒ€)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "summary": "ìš”ì•½",
    "sentiment_score": 0.0,
    "sentiment_label": "ì¤‘ë¦½",
    "key_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"],
    "issue_category": "ì •ì±…"
}}
"""
    
    structured_llm = llm_inference.with_structured_output(NewsAnalysisOutput)
    result = structured_llm.invoke(prompt)
    
    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {result.issue_category} ì´ìŠˆ, ê°ì„±={result.sentiment_label} (OpenAI)")
    
    return {
        "analysis": result.summary,
        "sentiment_score": result.sentiment_score,
        "sentiment_label": result.sentiment_label,
        "key_keywords": result.key_keywords,
        "issue_category": result.issue_category,
        "primary_retry_count": 0,
        "side_effect_retry_count": 0,
        "is_primary_valid": False,
        "is_side_effect_valid": False,
        "start_time": datetime.now(),
        "llm_call_count": 1,
        "openai_calls": 1,
        "warnings": []
    }

def primary_inference_node(state: AnalysisState):
    """[2] 1ì°¨ ìˆ˜í˜œì£¼ ì¶”ë¡  (OpenAI GPT ì‚¬ìš©)"""
    retry_num = state.get("primary_retry_count", 0)
    print(f"--- [2] 1ì°¨ ìˆ˜í˜œì£¼ ì¶”ë¡  (ì‹œë„ {retry_num + 1}íšŒ) (OpenAI GPT) ---")
    
    analysis = state["analysis"]
    feedback = state.get("primary_feedback", "")
    max_stocks = state.get("max_primary_stocks", 3)
    
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì‹œì¥ ë¶„ì„]
{analysis}

[ë¯¸ì…˜]
ìœ„ ì´ìŠˆë¡œ ê°€ì¥ ì§ì ‘ì ì¸ ìˆ˜í˜œë¥¼ ì…ì„ í•œêµ­ ìƒì¥ ì¢…ëª©ì„ {max_stocks}ê°œ ì¶”ì²œí•˜ì„¸ìš”.

[í•„ìˆ˜ ì¡°ê±´]
1. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•œêµ­ ì¢…ëª© (ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥)
2. ì¢…ëª©ì½”ë“œ 6ìë¦¬ í•„ìˆ˜ (ì˜ˆ: 005930=ì‚¼ì„±ì „ì, 000660=SKí•˜ì´ë‹‰ìŠ¤)
3. í™•ì‹ ë„ ì ìˆ˜ (0~100)
4. ì˜ˆìƒ ì¶”ì„¸ (up/down/neutral)
5. êµ¬ì²´ì ì¸ ìˆ˜í˜œ ì´ìœ 

[ì˜ˆì‹œ]
- ë°˜ë„ì²´ í˜¸í™© â†’ ì‚¼ì„±ì „ì(005930), SKí•˜ì´ë‹‰ìŠ¤(000660)
- ì „ê¸°ì°¨ ë³´ê¸‰ â†’ LGì—ë„ˆì§€ì†”ë£¨ì…˜(373220), ì‚¼ì„±SDI(006400)
"""
    
    if feedback:
        prompt += f"\n\n[ì´ì „ ì‹œë„ì—ì„œ ë°›ì€ ê²€ì¦ê´€ì˜ ì§€ì  (OpenAI GPT-4)]\n{feedback}\n\nâš ï¸ ìœ„ ì§€ì ì‚¬í•­ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”!"
    
    structured_llm = llm_inference.with_structured_output(PrimaryOutput)
    result = structured_llm.invoke(prompt)
    
    print(f"âœ… ì¶”ë¡  ì™„ë£Œ: {len(result.stocks)}ê°œ ì¢…ëª© (OpenAI)")
    for stock in result.stocks:
        print(f"   - {stock.name}({stock.code}): {stock.confidence_score:.0f}ì ")
    
    return {
        "primary_stocks": [s.dict() for s in result.stocks],
        "llm_call_count": state["llm_call_count"] + 1,
        "openai_calls": state["openai_calls"] + 1
    }

def primary_validation_node(state: AnalysisState):
    """[3] 1ì°¨ ìˆ˜í˜œì£¼ ê²€ì¦ (OpenAI GPT-4 ì‚¬ìš©)"""
    retry_num = state["primary_retry_count"]
    print(f"--- [3] 1ì°¨ ìˆ˜í˜œì£¼ ë…¼ë¦¬ ê²€ì¦ (ì‹œë„ {retry_num + 1}íšŒ) (OpenAI GPT-4) ---")
    
    stocks = state["primary_stocks"]
    analysis = state["analysis"]
    
    prompt = f"""ë‹¹ì‹ ì€ ë§¤ìš° ì—„ê²©í•œ ì£¼ì‹ ë¶„ì„ ê²€ì¦ê´€ì…ë‹ˆë‹¤. OpenAI GPTê°€ ì¶”ë¡ í•œ ì¢…ëª©ì„ ê²€ì¦í•˜ëŠ” ê²ƒì´ ì„ë¬´ì…ë‹ˆë‹¤.

[ì›ë³¸ ë‰´ìŠ¤ ë¶„ì„]
{analysis}

[OpenAI GPTê°€ ì¶”ë¡ í•œ ì¢…ëª©]
{stocks}

[ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸]
âœ… 1. ì¢…ëª©ì½”ë“œ ì‹¤ì¡´ì„±
   - 6ìë¦¬ ìˆ«ì í˜•ì‹ì¸ê°€?
   - ì‹¤ì œ í•œêµ­ ìƒì¥ ì¢…ëª©ì¸ê°€? (ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥)
   - ì˜ˆ: 005930(ì‚¼ì„±ì „ì), 000660(SKí•˜ì´ë‹‰ìŠ¤), 035720(ì¹´ì¹´ì˜¤)

âœ… 2. ë…¼ë¦¬ íƒ€ë‹¹ì„±
   - ë‰´ìŠ¤ ì´ìŠˆì™€ ì¢…ëª©ì˜ ì—°ê²°ì´ ì§ê´€ì ì´ê³  ëª…í™•í•œê°€?
   - "Aì´ê¸° ë•Œë¬¸ì— Bê°€ ìˆ˜í˜œë°›ëŠ”ë‹¤"ì˜ ë…¼ë¦¬ê°€ ì„±ë¦½í•˜ëŠ”ê°€?

âœ… 3. ê³¼ì¥ ì—¬ë¶€
   - ì§€ë‚˜ì¹˜ê²Œ ë¹„ì•½ì ì´ê±°ë‚˜ ì–µì§€ìŠ¤ëŸ¬ìš´ ì—°ê²°ì€ ì•„ë‹Œê°€?
   - ì‹¤ì œ ì‹œì¥ì—ì„œ ë°›ì•„ë“¤ì—¬ì§ˆ ë§Œí•œ ë…¼ë¦¬ì¸ê°€?

âœ… 4. ì§ì ‘ì„±
   - 1ì°¨ ì§ì ‘ ìˆ˜í˜œì£¼ì¸ê°€? (2ì°¨, 3ì°¨ íŒŒê¸‰íš¨ê³¼ëŠ” ë‚˜ì¤‘ ë‹¨ê³„)
   - ì´ìŠˆì™€ ì¦‰ê°ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆëŠ”ê°€?

[íŒì • ê¸°ì¤€]
- ìœ„ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë¼ë„ ë¬¸ì œ ìˆìœ¼ë©´: is_valid = False
- ëª¨ë‘ í†µê³¼í•˜ë©´: is_valid = True, feedback = "ê²€ì¦ í†µê³¼. ë…¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•¨."

ë¬¸ì œê°€ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì¢…ëª©ì˜ ì–´ë–¤ ë¶€ë¶„ì´ ë¬¸ì œì¸ì§€ ëª…ì‹œí•˜ì„¸ìš”.
"""
    
    structured_llm = llm_validation.with_structured_output(ValidationResult)
    result = structured_llm.invoke(prompt)
    
    status = "âœ… í†µê³¼" if result.is_valid else "âŒ ì¬ì‹œë„ í•„ìš”"
    print(f"{status} (OpenAI): {result.feedback[:100]}...")
    
    if result.issues:
        print(f"   ë°œê²¬ëœ ë¬¸ì œì :")
        for issue in result.issues:
            print(f"   - {issue}")
    
    warnings = []
    if result.confidence < 0.7:
        warnings.append(f"1ì°¨ ìˆ˜í˜œì£¼ ì‹ ë¢°ë„ ë‚®ìŒ ({result.confidence:.2f})")
    
    return {
        "primary_feedback": result.feedback,
        "primary_retry_count": state["primary_retry_count"] + 1,
        "is_primary_valid": result.is_valid,
        "llm_call_count": state["llm_call_count"] + 1,
        "openai_calls": state["openai_calls"] + 1,
        "warnings": state["warnings"] + warnings
    }

def technical_validation_node(state: AnalysisState):
    """
    [4] ê¸°ìˆ ì  ì§€í‘œ ê²€ì¦ (ì°¨íŠ¸ ë¶„ì„)
    ì¶”ì²œëœ ì¢…ëª©ì˜ ì°¨íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ 'ì„ ë°˜ì˜(ì´ë¯¸ ì˜¤ë¦„)' ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
    """
    print("--- [4] ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„ ì¤‘ (ì°¨íŠ¸ ê²€ì¦) ---")
    
    stocks = state["primary_stocks"]
    validated_stocks = []
    rejected_stocks = []
    
    import pandas as pd
    import numpy as np
    
    for stock in stocks:
        code = stock['code']
        name = stock['name']
        
        print(f"  ë¶„ì„ ì¤‘: {name}({code})")
        
        # 1. ì°¨íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        df = get_daily_price(code, days=100)
        
        if df is None or len(df) < 30:
            print(f"    âš ï¸ ì°¨íŠ¸ ë°ì´í„° ë¶€ì¡± - ìŠ¤í‚µ (ê·¸ëŒ€ë¡œ í†µê³¼)")
            stock['technical_status'] = "ë°ì´í„° ë¶€ì¡±"
            stock['technical_comment'] = "ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ (ê¸°ë³¸ í†µê³¼)"
            validated_stocks.append(stock)
            continue
        
        try:
            # === ì§€í‘œ ê³„ì‚° ===
            
            # A. RSI (14ì¼)
            delta = df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            current_rsi = rsi.iloc[-1]
            
            # B. ì´ê²©ë„ (20ì¼): (í˜„ì¬ê°€ / 20ì¼ì´ë™í‰ê· ) * 100
            ma_20 = df['Close'].rolling(window=20).mean()
            disparity = (df['Close'] / ma_20) * 100
            current_disparity = disparity.iloc[-1]
            
            # C. ë³¼ë¦°ì € ë°´ë“œ (20ì¼, ìŠ¹ìˆ˜ 2)
            std_dev = df['Close'].rolling(window=20).std()
            upper_band = ma_20 + (std_dev * 2)
            lower_band = ma_20 - (std_dev * 2)
            current_price = df['Close'].iloc[-1]
            current_upper = upper_band.iloc[-1]
            current_lower = lower_band.iloc[-1]
            current_ma = ma_20.iloc[-1]
            
            # === ëƒ‰ì •í•œ íŒì • (Logic) ===
            
            is_priced_in = False  # ì„ ë°˜ì˜ ë˜ì—ˆëŠ”ê°€?
            reasons = []
            score = 0  # ê³¼ì—´ ì ìˆ˜ (0-3ì )
            
            # ì¡°ê±´ 1: RSIê°€ 70 ì´ìƒì´ë©´ ê³¼ì—´
            if current_rsi >= 70:
                is_priced_in = True
                reasons.append(f"RSI ê³¼ì—´({current_rsi:.1f})")
                score += 1
            
            # ì¡°ê±´ 2: ì´ê²©ë„ê°€ 110% ì´ìƒì´ë©´ ë‹¨ê¸° ê¸‰ë“± ìƒíƒœ
            if current_disparity >= 110:
                is_priced_in = True
                reasons.append(f"ì´ê²©ë„ ê³¼ë‹¤({current_disparity:.1f}%)")
                score += 1
            
            # ì¡°ê±´ 3: í˜„ì¬ê°€ê°€ ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ì„ ëš«ì—ˆìœ¼ë©´ ê³ ì  ì§•í›„
            if current_price >= current_upper:
                is_priced_in = True
                reasons.append(f"ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ(${current_price:,.0f} â‰¥ ${current_upper:,.0f})")
                score += 1
            
            # === ê²°ë¡  ë„ì¶œ ===
            if not is_priced_in:
                # í†µê³¼! (ì•„ì§ ì‚´ ë§Œí•¨)
                stock['technical_status'] = "ì–‘í˜¸"
                stock['technical_score'] = f"RSI:{current_rsi:.1f}/ì´ê²©ë„:{current_disparity:.1f}%"
                
                if current_rsi < 30 or current_price < current_lower:
                    stock['technical_comment'] = "âœ… ì°¨íŠ¸ ë°”ë‹¥ê¶Œ. ìƒìŠ¹ ì—¬ë ¥ ë§¤ìš° ë†’ìŒ"
                elif current_rsi < 50 and current_disparity < 105:
                    stock['technical_comment'] = "âœ… ì°¨íŠ¸ ìƒìŠ¹ ì´ˆê¸°. ë§¤ìˆ˜ ì ê¸°"
                else:
                    stock['technical_comment'] = "âœ… ì°¨íŠ¸ ì •ìƒ ë²”ìœ„. ë§¤ìˆ˜ ìœ íš¨"
                
                validated_stocks.append(stock)
                print(f"    âœ… í†µê³¼: {stock['technical_comment']}")
                
            else:
                # íƒˆë½! (ì´ë¯¸ ë‹¤ ì˜¬ëìŒ)
                if score >= 2:
                    # 2ê°œ ì´ìƒ ê³¼ì—´ ì‹ í˜¸ â†’ ì™„ì „ íƒˆë½
                    stock['technical_status'] = "ê³¼ì—´"
                    stock['technical_comment'] = f"âŒ {', '.join(reasons)} - ì„ ë°˜ì˜ë¨"
                    rejected_stocks.append(stock)
                    print(f"    âŒ íƒˆë½: {stock['technical_comment']}")
                else:
                    # 1ê°œë§Œ ê³¼ì—´ â†’ ê²½ê³ ì™€ í•¨ê»˜ í†µê³¼
                    stock['technical_status'] = "ì£¼ì˜"
                    stock['technical_comment'] = f"âš ï¸ {', '.join(reasons)} - ì£¼ì˜ í•„ìš”"
                    validated_stocks.append(stock)
                    print(f"    âš ï¸ ì¡°ê±´ë¶€ í†µê³¼: {stock['technical_comment']}")
                    
        except Exception as e:
            print(f"    âš ï¸ ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e} - ê¸°ë³¸ í†µê³¼")
            stock['technical_status'] = "ê³„ì‚° ì˜¤ë¥˜"
            stock['technical_comment'] = f"ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨ (ê¸°ë³¸ í†µê³¼)"
            validated_stocks.append(stock)
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n  ğŸ“Š ê¸°ìˆ ì  ê²€ì¦ ê²°ê³¼:")
    print(f"    âœ… í†µê³¼: {len(validated_stocks)}ê°œ")
    print(f"    âŒ íƒˆë½: {len(rejected_stocks)}ê°œ")
    
    if rejected_stocks:
        print(f"    íƒˆë½ ì¢…ëª©: {', '.join([s['name'] for s in rejected_stocks])}")
    
    warnings = []
    if len(validated_stocks) == 0:
        warnings.append("âš ï¸ ëª¨ë“  ì¢…ëª©ì´ ê¸°ìˆ ì ìœ¼ë¡œ ê³¼ì—´ - ì¶”ì²œ ë¶ˆê°€")
    elif len(rejected_stocks) > 0:
        warnings.append(f"{len(rejected_stocks)}ê°œ ì¢…ëª©ì´ ì°¨íŠ¸ ê³¼ì—´ë¡œ ì œì™¸ë¨")
    
    return {
        "primary_stocks": validated_stocks,
        "technical_rejected": rejected_stocks,
        "warnings": state["warnings"] + warnings
    }

def side_effect_inference_node(state: AnalysisState):
    """[5] 2ì°¨ íŒŒê¸‰íš¨ê³¼ ì¶”ë¡  (OpenAI GPT ì‚¬ìš©)"""
    retry_num = state.get("side_effect_retry_count", 0)
    print(f"--- [5] 2ì°¨ íŒŒê¸‰íš¨ê³¼ ì¶”ë¡  (ì‹œë„ {retry_num + 1}íšŒ) (OpenAI GPT) ---")
    
    analysis = state["analysis"]
    primary_stocks = state["primary_stocks"]
    feedback = state.get("side_effect_feedback", "")
    max_effects = state.get("max_side_effects", 2)
    
    prompt = f"""ë‹¹ì‹ ì€ ì‚°ì—… ì—°ê´€ê´€ê³„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì°½ì˜ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” 2ì°¨ íŒŒê¸‰íš¨ê³¼ë¥¼ ì°¾ì•„ë‚´ì„¸ìš”.

[ì‹œì¥ ì´ìŠˆ]
{analysis}

[1ì°¨ ì§ì ‘ ìˆ˜í˜œì£¼]
{primary_stocks}

[ë¯¸ì…˜]
1ì°¨ ìˆ˜í˜œì£¼ê°€ ìƒìŠ¹í•˜ê±°ë‚˜ ì´ìŠˆê°€ ì§€ì†ë  ë•Œ, ì—°ì‡„ì ìœ¼ë¡œ ìˆ˜í˜œë¥¼ ë°›ì„ ì‚°ì—…ê³¼ ì¢…ëª©ì„ ìµœëŒ€ {max_effects}ê°œ ì¶”ë¡ í•˜ì„¸ìš”.

[íŒŒê¸‰ ì²´ì¸ ì˜ˆì‹œ]
1ï¸âƒ£ ì „ê¸°ì°¨ íŒë§¤ ì¦ê°€
   â†’ ë°°í„°ë¦¬ ìˆ˜ìš” ì¦ê°€ (1ì°¨: ì‚¼ì„±SDI, LGì—ë„ˆì§€ì†”ë£¨ì…˜)
   â†’ ë°°í„°ë¦¬ ì†Œì¬ ìˆ˜ìš” ì¦ê°€ (2ì°¨: í¬ìŠ¤ì½”ì¼€ë¯¸ì¹¼, ì—ì½”í”„ë¡œë¹„ì— )
   â†’ íë°°í„°ë¦¬ ì¬í™œìš© í•„ìš” (2ì°¨: ì„±ì¼í•˜ì´í…, íŒŒì›Œë¡œì§ìŠ¤)

2ï¸âƒ£ ë°˜ë„ì²´ íˆ¬ì í™•ëŒ€
   â†’ ë°˜ë„ì²´ ì¥ë¹„ ìˆ˜ìš” (1ì°¨: ì£¼ì„±ì—”ì§€ë‹ˆì–´ë§, ì›ìµIPS)
   â†’ ë°˜ë„ì²´ ì†Œì¬ ìˆ˜ìš” (2ì°¨: ì†”ë¸Œë ˆì¸, SKë¨¸í‹°ë¦¬ì–¼ì¦ˆ)
   â†’ ì •ë°€ ë¶€í’ˆ ìˆ˜ìš” (2ì°¨: í…ŒìŠ¤, ì½”ì„¸ìŠ¤)

3ï¸âƒ£ K-ì½˜í…ì¸  ìˆ˜ì¶œ ì¦ê°€
   â†’ ì—”í„°í…Œì¸ë¨¼íŠ¸ ê¸°ì—… (1ì°¨: HYBE, SM, JYP)
   â†’ í”Œë«í¼/ìœ í†µì‚¬ (2ì°¨: ë„·ë§ˆë¸”, ì¹´ì¹´ì˜¤ì—”í„°)
   â†’ ì œì‘ì‚¬/ìŠ¤íŠœë””ì˜¤ (2ì°¨: ìŠ¤íŠœë””ì˜¤ë“œë˜ê³¤, ì—ì´ìŠ¤í† ë¦¬)

[ì¶œë ¥ í˜•ì‹]
ê° ì‚°ì—…ë³„ë¡œ:
- sector: ì‚°ì—…ëª… (ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ)
- logic: A â†’ B â†’ C í˜•íƒœì˜ íŒŒê¸‰ ë…¼ë¦¬
- impact_level: high/medium/low
- trend_direction: positive/negative/neutral
- related_stocks: ê´€ë ¨ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ì¢…ëª©ì½”ë“œ 6ìë¦¬ + ì¢…ëª©ëª…)
"""
    
    if feedback:
        prompt += f"\n\n[ì´ì „ ì‹œë„ì—ì„œ ë°›ì€ ê²€ì¦ê´€ì˜ ì§€ì  (OpenAI GPT-4)]\n{feedback}\n\nâš ï¸ ë…¼ë¦¬ë¥¼ ë” êµ¬ì²´í™”í•˜ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ìˆ˜ì •í•˜ì„¸ìš”!"
    
    structured_llm = llm_inference.with_structured_output(SideEffectOutput)
    result = structured_llm.invoke(prompt)
    
    print(f"âœ… ì¶”ë¡  ì™„ë£Œ: {len(result.effects)}ê°œ ì‚°ì—… (OpenAI)")
    for effect in result.effects:
        print(f"   - {effect.sector} ({effect.impact_level}): {len(effect.related_stocks)}ê°œ ì¢…ëª©")
    
    return {
        "side_effects": [e.dict() for e in result.effects],
        "llm_call_count": state["llm_call_count"] + 1,
        "openai_calls": state["openai_calls"] + 1
    }

def side_effect_validation_node(state: AnalysisState):
    """[6] íŒŒê¸‰íš¨ê³¼ ê²€ì¦ (OpenAI GPT-4 ì‚¬ìš©)"""
    retry_num = state["side_effect_retry_count"]
    print(f"--- [6] íŒŒê¸‰íš¨ê³¼ ê²€ì¦ (ì‹œë„ {retry_num + 1}íšŒ) (OpenAI GPT-4) ---")
    
    effects = state["side_effects"]
    primary_stocks = state["primary_stocks"]
    
    prompt = f"""ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì¸ê³¼ê´€ê³„ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. OpenAI GPTê°€ ì¶”ë¡ í•œ íŒŒê¸‰íš¨ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ê²ƒì´ ì„ë¬´ì…ë‹ˆë‹¤.

[1ì°¨ ìˆ˜í˜œì£¼]
{primary_stocks}

[OpenAI GPTê°€ ì¶”ë¡ í•œ 2ì°¨ íŒŒê¸‰íš¨ê³¼]
{effects}

[ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸]
âœ… 1. ì¸ê³¼ê´€ê³„ ëª…í™•ì„±
   - A â†’ B â†’ Cì˜ ì—°ê²°ê³ ë¦¬ê°€ ë…¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•œê°€?
   - ê° ë‹¨ê³„ì˜ ì¸ê³¼ê´€ê³„ê°€ ì‹¤ì œë¡œ ì„±ë¦½í•˜ëŠ”ê°€?

âœ… 2. ì‹¤í˜„ ê°€ëŠ¥ì„±
   - ì‹¤ì œë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì¸ê°€?
   - ê³¼ê±° ì‚¬ë¡€ë‚˜ ì‹œì¥ ê²½í—˜ìƒ í•©ë¦¬ì ì¸ê°€?

âœ… 3. ë¹„ì•½ ì—¬ë¶€
   - ë„ˆë¬´ ì–µì§€ìŠ¤ëŸ½ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì´ì§€ ì•Šì€ê°€?
   - 1ì°¨ â†’ 2ì°¨ë¡œì˜ ì í”„ê°€ ìì—°ìŠ¤ëŸ¬ìš´ê°€?

âœ… 4. ì‹œì¥ í•©ë¦¬ì„±
   - ì‹¤ì œ íˆ¬ììë“¤ì´ ì´ ë…¼ë¦¬ë¥¼ ë°›ì•„ë“¤ì¼ ë§Œí•œê°€?
   - ì¶”ì²œëœ ì¢…ëª©ë“¤ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ê´€ë ¨ì„±ì´ ìˆëŠ”ê°€?

[íŒì • ê¸°ì¤€]
- ëª¨ë“  ê¸°ì¤€ í†µê³¼: is_valid = True
- ì¼ë¶€ ë¬¸ì œ: is_valid = False + êµ¬ì²´ì  ìˆ˜ì •ì‚¬í•­ ëª…ì‹œ

ë¬¸ì œê°€ ìˆë‹¤ë©´ ì–´ë–¤ ì‚°ì—…ì˜ ì–´ë–¤ ë…¼ë¦¬ê°€ ë¬¸ì œì¸ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”.
"""
    
    structured_llm = llm_validation.with_structured_output(ValidationResult)
    result = structured_llm.invoke(prompt)
    
    status = "âœ… í†µê³¼" if result.is_valid else "âŒ ì¬ì‹œë„ í•„ìš”"
    print(f"{status} (OpenAI): {result.feedback[:100]}...")
    
    if result.issues:
        print(f"   ë°œê²¬ëœ ë¬¸ì œì :")
        for issue in result.issues:
            print(f"   - {issue}")
    
    warnings = []
    if result.confidence < 0.6:
        warnings.append(f"íŒŒê¸‰íš¨ê³¼ ì‹ ë¢°ë„ ë‚®ìŒ ({result.confidence:.2f})")
    
    return {
        "side_effect_feedback": result.feedback,
        "side_effect_retry_count": state["side_effect_retry_count"] + 1,
        "is_side_effect_valid": result.is_valid,
        "llm_call_count": state["llm_call_count"] + 1,
        "openai_calls": state["openai_calls"] + 1,
        "warnings": state["warnings"] + warnings
    }

# ==================== Edge Conditions ====================

def check_primary(state: AnalysisState):
    """1ì°¨ ê²€ì¦ í†µê³¼ ì—¬ë¶€"""
    is_valid = state.get("is_primary_valid", False)
    retry_count = state.get("primary_retry_count", 0)
    max_retry = state.get("max_retry", 3)
    
    if is_valid or retry_count >= max_retry:
        if retry_count >= max_retry and not is_valid:
            print(f"âš ï¸ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬, ê°•ì œ í†µê³¼ (OpenAIê°€ {max_retry}íšŒ ì‹œë„)")
        return "pass"
    return "retry"

def check_side_effect(state: AnalysisState):
    """2ì°¨ ê²€ì¦ í†µê³¼ ì—¬ë¶€"""
    is_valid = state.get("is_side_effect_valid", False)
    retry_count = state.get("side_effect_retry_count", 0)
    max_retry = state.get("max_retry", 3)
    
    if is_valid or retry_count >= max_retry:
        if retry_count >= max_retry and not is_valid:
            print(f"âš ï¸ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬, ê°•ì œ í†µê³¼ (Geminiê°€ {max_retry}íšŒ ì‹œë„)")
        return "pass"
    return "retry"

# ==================== Graph Construction ====================

workflow = StateGraph(AnalysisState)

workflow.add_node("analyze_news", analyze_news_node)
workflow.add_node("primary_inference", primary_inference_node)
workflow.add_node("primary_validation", primary_validation_node)
workflow.add_node("technical_validation", technical_validation_node)  # ğŸ“ˆ ìƒˆë¡œ ì¶”ê°€
workflow.add_node("side_effect_inference", side_effect_inference_node)
workflow.add_node("side_effect_validation", side_effect_validation_node)

workflow.set_entry_point("analyze_news")
workflow.add_edge("analyze_news", "primary_inference")
workflow.add_edge("primary_inference", "primary_validation")

workflow.add_conditional_edges(
    "primary_validation",
    check_primary,
    {"pass": "technical_validation", "retry": "primary_inference"}  # ë…¼ë¦¬ ê²€ì¦ í†µê³¼ â†’ ì°¨íŠ¸ ê²€ì¦
)

workflow.add_edge("technical_validation", "side_effect_inference")  # ì°¨íŠ¸ ê²€ì¦ â†’ íŒŒê¸‰íš¨ê³¼

workflow.add_edge("side_effect_inference", "side_effect_validation")

workflow.add_conditional_edges(
    "side_effect_validation",
    check_side_effect,
    {"pass": END, "retry": "side_effect_inference"}
)

app = workflow.compile()

# ==================== DB Integration ====================

def save_to_database(
    db: Session,
    news_articles: List[NewsArticle],
    state: AnalysisState,
    analysis_date: date
) -> Report:
    """LangGraph ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ì¡´ DB ìŠ¤í‚¤ë§ˆì— ì €ì¥"""
    print("--- [7] ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹œì‘ ---")
    
    # Report ìƒì„±
    report = Report(
        title=f"{analysis_date.strftime('%Y-%m-%d')} ì£¼ì‹ ë™í–¥ ë¶„ì„ (OpenAI AI)",
        summary=state["analysis"],
        analysis_date=analysis_date
    )
    db.add(report)
    db.flush()
    
    # ë‰´ìŠ¤ ì—°ê²°
    for news in news_articles:
        report.news_articles.append(news)
    
    # 1ì°¨ ìˆ˜í˜œì£¼ë¥¼ ì²« ë²ˆì§¸ ì‚°ì—…ìœ¼ë¡œ ì €ì¥
    primary_industry = ReportIndustry(
        report_id=report.id,
        industry_name="1ì°¨ ì§ì ‘ ìˆ˜í˜œì£¼",
        impact_level="high",
        impact_description=f"ë‰´ìŠ¤ ì´ìŠˆ({state['issue_category']})ë¡œ ì¸í•œ ì§ì ‘ ìˆ˜í˜œ",
        trend_direction="positive" if state.get("sentiment_score", 0) > 0 else "neutral"
    )
    db.add(primary_industry)
    db.flush()
    
    # 1ì°¨ ìˆ˜í˜œì£¼ ì €ì¥
    for stock_data in state["primary_stocks"]:
        stock = ReportStock(
            report_id=report.id,
            industry_id=primary_industry.id,
            stock_code=stock_data["code"],
            stock_name=stock_data["name"],
            expected_trend=stock_data.get("expected_trend", "up"),
            confidence_score=stock_data.get("confidence_score", 50.0) / 100.0,
            reasoning=stock_data["reason"]
        )
        db.add(stock)
    
    # 2ì°¨ íŒŒê¸‰íš¨ê³¼ (ì‚°ì—…ë³„ë¡œ ì €ì¥)
    for effect_data in state["side_effects"]:
        industry = ReportIndustry(
            report_id=report.id,
            industry_name=effect_data["sector"],
            impact_level=effect_data.get("impact_level", "medium"),
            impact_description=effect_data["logic"],
            trend_direction=effect_data.get("trend_direction", "positive")
        )
        db.add(industry)
        db.flush()
        
        # ê´€ë ¨ ì¢…ëª© ì €ì¥
        for stock_data in effect_data.get("related_stocks", []):
            stock = ReportStock(
                report_id=report.id,
                industry_id=industry.id,
                stock_code=stock_data["code"],
                stock_name=stock_data["name"],
                expected_trend=stock_data.get("expected_trend", "up"),
                confidence_score=stock_data.get("confidence_score", 50.0) / 100.0,
                reasoning=stock_data["reason"]
            )
            db.add(stock)
    
    db.commit()
    db.refresh(report)
    
    print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: Report ID={report.id}")
    return report

# ==================== Main API Function ====================

def analyze_news_with_langgraph(
    db: Session,
    news_articles: List[NewsArticle],
    max_primary_stocks: int = 3,
    max_side_effects: int = 2,
    max_retry: int = 3,
    analysis_date: Optional[date] = None
) -> Report:
    """
    ë‰´ìŠ¤ë¥¼ OpenAI GPTë¡œ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ DBì— ì €ì¥
    - ì¶”ë¡ : OpenAI GPT-4o-mini (ë¹ ë¥´ê³  ì €ë ´)
    - ê²€ì¦: OpenAI GPT-4o-mini (ì •í™•í•˜ê³  ì—„ê²©)
    """
    if not news_articles:
        raise ValueError("ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    if analysis_date is None:
        analysis_date = date.today()
    
    print(f"==================== OpenAI AI ë¶„ì„ ì‹œì‘ ====================")
    print(f"ë‰´ìŠ¤ ê°œìˆ˜: {len(news_articles)}")
    print(f"ì˜µì…˜: primary={max_primary_stocks}, side={max_side_effects}, retry={max_retry}")
    print(f"ì „ëµ: ì¶”ë¡ (OpenAI GPT) + ê²€ì¦(OpenAI GPT)")
    print(f"=" * 60)
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "news_articles": news_articles,
        "max_primary_stocks": max_primary_stocks,
        "max_side_effects": max_side_effects,
        "max_retry": max_retry
    }
    
    try:
        # LangGraph ì‹¤í–‰
        result = app.invoke(initial_state)
        
        # ê²°ê³¼ ì¶œë ¥
        end_time = datetime.now()
        processing_time = (end_time - result["start_time"]).total_seconds()
        
        print(f"\n{'=' * 60}")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ")
        print(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"ì´ LLM í˜¸ì¶œ: {result['llm_call_count']}íšŒ")
        print(f"  â””â”€ OpenAI GPT: {result['openai_calls']}íšŒ")
        print(f"ì´ ë°˜ë³µ íšŸìˆ˜: {result['primary_retry_count']}íšŒ (1ì°¨) + {result['side_effect_retry_count']}íšŒ (2ì°¨)")
        print(f"{'=' * 60}\n")
        
        # 3. ê²°ê³¼ DB ì €ì¥ ë° ë°˜í™˜
        report = save_to_database(db, news_articles, result, analysis_date)
        return report

    except Exception as e:
        import traceback
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        raise 

# ==================== Backward Compatibility ====================

def analyze_and_save(
    db: Session,
    news_articles: List[NewsArticle],
    analysis_date: Optional[date] = None
) -> Report:
    """
    ê¸°ì¡´ APIì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
    
    ê¸°ì¡´ ì½”ë“œì—ì„œ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ LangGraph ì‚¬ìš©
    """
    return analyze_news_with_langgraph(
        db=db,
        news_articles=news_articles,
        analysis_date=analysis_date
    )


def analyze_news_from_vector_db(
    db: Session,
    start_datetime: Optional[datetime] = None,
    end_datetime: Optional[datetime] = None,
    analysis_date: Optional[date] = None
) -> Report:
    """
    ë²¡í„° DBì—ì„œ ë‚ ì§œ ë²”ìœ„ë¡œ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•˜ê³ , AI ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        start_datetime: ì‹œì‘ ë‚ ì§œ/ì‹œê°„ (ê¸°ë³¸ê°’: ì „ë‚  06:00:00)
        end_datetime: ì¢…ë£Œ ë‚ ì§œ/ì‹œê°„ (ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„)
        analysis_date: ë¶„ì„ ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    
    Returns:
        ìƒì„±ëœ Report ê°ì²´
    
    Raises:
        ValueError: ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ë¶„ì„ ì‹¤íŒ¨ ì‹œ
    """
    from datetime import timedelta
    import pytz
    
    # í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
    seoul_tz = pytz.timezone('Asia/Seoul')
    now = datetime.now(seoul_tz)
    
    # ê¸°ë³¸ê°’ ì„¤ì •: ì „ë‚  06:00 ~ í˜„ì¬ ì‹œê°„
    if end_datetime is None:
        end_datetime = now
    else:
        if end_datetime.tzinfo is None:
            end_datetime = seoul_tz.localize(end_datetime)
    
    if start_datetime is None:
        yesterday = (now - timedelta(days=1)).replace(hour=6, minute=0, second=0, microsecond=0)
        start_datetime = yesterday
    else:
        if start_datetime.tzinfo is None:
            start_datetime = seoul_tz.localize(start_datetime)
    
    if analysis_date is None:
        analysis_date = date.today()
    
    # ë²¡í„° DBì—ì„œ ë‰´ìŠ¤ ì¡°íšŒ (ë‚ ì§œ ë²”ìœ„ë¡œ)
    # metadataì˜ published_dateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°íšŒ
    from sqlalchemy import text
    
    try:
        sqlalchemy_conn = db.connection()
        raw_conn = None
        if hasattr(sqlalchemy_conn, 'connection'):
            raw_conn = sqlalchemy_conn.connection
            if hasattr(raw_conn, 'driver_connection'):
                raw_conn = raw_conn.driver_connection
        else:
            raw_conn = sqlalchemy_conn
        
        cursor = raw_conn.cursor()
        
        try:
            start_str = start_datetime.isoformat()
            end_str = end_datetime.isoformat()
            
            cursor.execute("""
                SELECT id FROM news_articles
                WHERE metadata IS NOT NULL
                AND metadata->>'published_date' IS NOT NULL
                AND (
                    (metadata->>'published_date')::timestamp >= %s::timestamp
                    AND (metadata->>'published_date')::timestamp <= %s::timestamp
                )
                ORDER BY (metadata->>'published_date')::timestamp DESC
                LIMIT 20
            """, (start_str, end_str))
            
            article_ids = [row[0] for row in cursor.fetchall()]
            news_articles = db.query(NewsArticle).filter(NewsArticle.id.in_(article_ids)).all() if article_ids else []
            
            print(f"âœ… ë²¡í„° DBì—ì„œ ë‰´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {len(news_articles)}ê°œ (ê¸°ê°„: {start_datetime.strftime('%Y-%m-%d %H:%M')} ~ {end_datetime.strftime('%Y-%m-%d %H:%M')})")
        finally:
            cursor.close()
        
    except Exception as e:
        import traceback
        print(f"âš ï¸  ë²¡í„° DB ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        print(f"Traceback: {traceback.format_exc()}")
        raise ValueError(f"ë²¡í„° DBì—ì„œ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    if not news_articles:
        raise ValueError(f"ì¡°íšŒëœ ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„: {start_datetime} ~ {end_datetime})")
    
    # ë¶„ì„ ë° ì €ì¥
    report = analyze_news_with_langgraph(
        db=db,
        news_articles=news_articles,
        analysis_date=analysis_date
    )
    
    print(f"âœ… ë²¡í„° DB ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ: ë³´ê³ ì„œ ID={report.id}, ë‰´ìŠ¤ {len(news_articles)}ê°œ ë¶„ì„")
    
    return report


# ==================== í•œêµ­íˆ¬ìì¦ê¶Œ API í•¨ìˆ˜ ====================

KIS_APP_KEY = os.getenv("KIS_APP_KEY")
KIS_APP_SECRET = os.getenv("KIS_APP_SECRET")
KIS_ACCESS_TOKEN = None

def get_kis_access_token():
    """í•œêµ­íˆ¬ìì¦ê¶Œ API í† í° ë°œê¸‰"""
    global KIS_ACCESS_TOKEN
    
    if not KIS_APP_KEY or not KIS_APP_SECRET:
        print("âš ï¸ í•œíˆ¬ API í‚¤ ì—†ìŒ - ê¸°ìˆ ì  ê²€ì¦ ìŠ¤í‚µ")
        return None
    
    if KIS_ACCESS_TOKEN:
        return KIS_ACCESS_TOKEN
    
    url = "https://openapi.koreainvestment.com:9443/oauth2/tokenP"
    headers = {"content-type": "application/json"}
    body = {
        "grant_type": "client_credentials",
        "appkey": KIS_APP_KEY,
        "appsecret": KIS_APP_SECRET
    }
    
    try:
        import requests
        response = requests.post(url, headers=headers, json=body)
        if response.status_code == 200:
            KIS_ACCESS_TOKEN = response.json()["access_token"]
            print("âœ… í•œíˆ¬ API í† í° ë°œê¸‰ ì„±ê³µ")
            return KIS_ACCESS_TOKEN
    except Exception as e:
        print(f"âš ï¸ í•œíˆ¬ API í† í° ë°œê¸‰ ì‹¤íŒ¨: {e}")
    
    return None


def get_daily_price(stock_code: str, days: int = 100):
    """
    í•œêµ­íˆ¬ìì¦ê¶Œ APIë¡œ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ
    
    Args:
        stock_code: ì¢…ëª©ì½”ë“œ (6ìë¦¬)
        days: ì¡°íšŒí•  ì¼ìˆ˜
    
    Returns:
        DataFrame with columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
    """
    token = get_kis_access_token()
    if not token:
        return None
    
    url = "https://openapi.koreainvestment.com:9443/uapi/domestic-stock/v1/quotations/inquire-daily-price"
    headers = {
        "content-type": "application/json",
        "authorization": f"Bearer {token}",
        "appkey": KIS_APP_KEY,
        "appsecret": KIS_APP_SECRET,
        "tr_id": "FHKST01010400"
    }
    
    params = {
        "FID_COND_MRKT_DIV_CODE": "J",
        "FID_INPUT_ISCD": stock_code,
        "FID_PERIOD_DIV_CODE": "D",
        "FID_ORG_ADJ_PRC": "0"
    }
    
    try:
        import requests
        import pandas as pd
        
        response = requests.get(url, headers=headers, params=params)
        
        if response.status_code != 200:
            print(f"âš ï¸ {stock_code} ì°¨íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
            return None
        
        data = response.json()
        if data.get("rt_cd") != "0":
            print(f"âš ï¸ {stock_code} ë°ì´í„° ì—†ìŒ")
            return None
        
        output = data.get("output", [])
        if not output:
            return None
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(output[:days])
        df = df.rename(columns={
            "stck_bsop_date": "Date",
            "stck_oprc": "Open",
            "stck_hgpr": "High",
            "stck_lwpr": "Low",
            "stck_clpr": "Close",
            "acml_vol": "Volume"
        })
        
        # ìˆ«ì ë³€í™˜
        for col in ["Open", "High", "Low", "Close", "Volume"]:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df = df.sort_values("Date").reset_index(drop=True)
        
        return df[["Date", "Open", "High", "Low", "Close", "Volume"]]
        
    except Exception as e:
        print(f"âš ï¸ {stock_code} ì°¨íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None
